import java.text.SimpleDateFormat;
import java.util.Arrays;

import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.conf.Configured;
import org.apache.hadoop.hbase.HBaseConfiguration;
import org.apache.hadoop.hbase.KeyValue;
import org.apache.hadoop.hbase.client.Delete;
import org.apache.hadoop.hbase.client.Get;
import org.apache.hadoop.hbase.client.HTable;
import org.apache.hadoop.hbase.client.Result;
import org.apache.hadoop.hbase.client.ResultScanner;
import org.apache.hadoop.hbase.client.Scan;
import org.apache.hadoop.hbase.io.ImmutableBytesWritable;
import org.apache.hadoop.hbase.mapreduce.TableMapReduceUtil;
import org.apache.hadoop.hbase.util.Bytes;
import org.apache.hadoop.io.IntWritable;
import org.apache.hadoop.io.LongWritable;
import org.apache.hadoop.mapreduce.Job;
import org.apache.hadoop.util.Tool;
import org.apache.hadoop.util.ToolRunner;


public class Task5B extends Configured implements Tool {
	
	public int run(String[] arg) throws Exception{
		//Set configuration
		Configuration conf = HBaseConfiguration.create(getConf());
		//conf.set("hbase.zookeeper.quorum", "bigdata-06.dcs.gla.ac.uk");
		conf.addResource("all-client-conf.xml");

		//Point to Jar
		conf.set("mapred.jar", "file:///users/level4/1002386c/Documents/BD4/AE2/Q5B.jar");
		
		//Setup job
		Job job = new Job(conf);
		job.setJarByClass(Task5B.class);
		
		//Set up Scanner
		//CF "WD" for sample dataset
		Scan scan = new Scan();
		scan.addColumn(Bytes.toBytes("q1"), Bytes.toBytes("in_artid"));
		scan.addColumn(Bytes.toBytes("q1"), Bytes.toBytes("in_revid"));
		scan.setCaching(100);
		scan.setCacheBlocks(false);
		
		job.getConfiguration().setStrings("date", arg[0]);
		
		//Run Mapper
		TableMapReduceUtil.initTableMapperJob(
				"1002386c",
				scan,
				T5BMapper.class,
				ImmutableBytesWritable.class,
				ImmutableBytesWritable.class,
				job);
		
		TableMapReduceUtil.initTableReducerJob(
				"1002386c",
				T5BReducer.class,
				job);
		job.setNumReduceTasks(1);
		
		//Keep note of job status in order to return run status
		boolean status = job.waitForCompletion(true);
		
		//Read created table to output data to stdout
		
		HTable hTable = new HTable(conf, "1002386c");
		ResultScanner scanner = hTable.getScanner(Bytes.toBytes("q5"),Bytes.toBytes("revidts"));
		
		//Declare SDF to format timestamp
		SimpleDateFormat dateFormat = new SimpleDateFormat("yyyy-MM-dd'T'HH:mm:ss'Z'");
		
		System.out.println("RESULTS:");
		for (Result res : scanner) {
			//Split value into revid & timestamp
			long revid = Bytes.toLong(Arrays.copyOfRange(res.value(), 0, 8));
			long ts = Bytes.toLong(Arrays.copyOfRange(res.value(), 8, res.value().length));
			
			//Format timestamp
			
			
			System.out.println(Bytes.toLong(res.getRow()) + " " + revid + " " + dateFormat.format(ts));
		}
		
		//Delete data after output
		Delete delete = new Delete(Bytes.toBytes("b"));
		delete.deleteColumns(Bytes.toBytes("q5"), Bytes.toBytes("revidts"));
		hTable.delete(delete);
		
		
		scanner.close();
		hTable.close();
		
		return status ? 0 : 1;
	}
	
	public static void main(String[] args) throws Exception{
		System.exit(ToolRunner.run(new Task5B(), args));
	}
}
